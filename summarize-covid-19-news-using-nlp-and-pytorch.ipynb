{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28670142",
   "metadata": {},
   "source": [
    "# Summarizing Covid-19 News Using NLP and Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0ea67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os, glob\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0bdd265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7fac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "webhose_2019_12 = 'datasubset/16119_webhose_2019_12_db21c91a1ab47385bb13773ed8238c31_0000001.json'\n",
    "webhose_2020_01 = 'datasubset/16119_webhose_2020_01_db21c91a1ab47385bb13773ed8238c31_0000001.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a7621",
   "metadata": {},
   "source": [
    "## Download and extract the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac48fd",
   "metadata": {},
   "source": [
    "Read each of those files, extract the value of the text key and title key from those objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a27771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "target = []\n",
    "for filename in [webhose_2019_12, webhose_2020_01]:\n",
    "    with open(filename, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        dataset.append(result['text'])\n",
    "        target.append(result['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739234d6",
   "metadata": {},
   "source": [
    "The length of the list dataset and target will be 94403. So essentially our dataset size is about 100K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f516f421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94403, 94403)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b229d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global Swine Healthcare Market by Products, Diseases & Geography – Forecast to 2024',\n",
       " 'FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases',\n",
       " 'C-Suite Awards: Regina Yan',\n",
       " 'FDA Launches Infectious Disease Crowdsourcing App for Clinicians FDA Launches Infectious Disease Crowdsourcing App for Clinicians',\n",
       " 'Drug Safety Oversight Board',\n",
       " 'How Prepared Are We For The Next Pandemic? Not Very, Experts Show',\n",
       " 'Suspected MERS case reported',\n",
       " 'Factors associated with and barriers to disclosure of a sexual assault to formal on-campus resources among college students - Mennicke A, Bowling J, Gromer J, Ryan C.',\n",
       " \"The effect of university students' violence tendency on their attitude towards domestic violence and the factors affecting domestic violence attitudes - Yagiz R, Sevil U, Guner Ö.\",\n",
       " 'YoYo Discusses Career, Teaching and Female Empowerment']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e3387",
   "metadata": {},
   "source": [
    "## Text cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5f3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contraction_hashmap import contraction_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c03a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower() # lowercase\n",
    "    text = text.split() # convert have'nt -> have not\n",
    "    for i in range(len(text)):\n",
    "        word = text[i]\n",
    "        if word in contraction_map:\n",
    "            text[i] = contraction_map[word]\n",
    "    text = \" \".join(text)\n",
    "    text = text.split()\n",
    "    newtext = []\n",
    "    for word in text:\n",
    "        if word not in stop_words:\n",
    "            newtext.append(word)\n",
    "    text = \" \".join(newtext)\n",
    "    text = text.replace(\"'s\",'') # convert your's -> your\n",
    "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
    "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
    "    text = re.sub(r'\\.',' . ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad25071",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [preprocess(text) for text in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afde2f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94403"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5040170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [preprocess(text) for text in target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90ddda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94403"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b1947d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text = 600\n",
    "max_len_target = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c99e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    if(len(target[i].split())<=max_len_target and len(dataset[i].split())<=max_len_text):\n",
    "        short_text.append(dataset[i])\n",
    "        short_summary.append(target[i])\n",
    "\n",
    "temp_df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7bb716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA launches app for health care professionals...</td>\n",
       "      <td>FDA launches app for health care professionals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of all of Regina Yan ’s many traits, an open m...</td>\n",
       "      <td>C-Suite Awards: Regina Yan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The CURE ID app allows clinicians to share and...</td>\n",
       "      <td>FDA Launches Infectious Disease Crowdsourcing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The DSB is composed of representatives from tw...</td>\n",
       "      <td>Drug Safety Oversight Board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Centre for Health Protection (CHP) of the ...</td>\n",
       "      <td>Suspected MERS case reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  FDA launches app for health care professionals...   \n",
       "1  Of all of Regina Yan ’s many traits, an open m...   \n",
       "2  The CURE ID app allows clinicians to share and...   \n",
       "3  The DSB is composed of representatives from tw...   \n",
       "4  The Centre for Health Protection (CHP) of the ...   \n",
       "\n",
       "                                             summary  \n",
       "0  FDA launches app for health care professionals...  \n",
       "1                         C-Suite Awards: Regina Yan  \n",
       "2  FDA Launches Infectious Disease Crowdsourcing ...  \n",
       "3                        Drug Safety Oversight Board  \n",
       "4                       Suspected MERS case reported  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd40fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64893 entries, 0 to 64892\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     64893 non-null  object\n",
      " 1   summary  64893 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1014.1+ KB\n"
     ]
    }
   ],
   "source": [
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b8743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = temp_df[temp_df['summary'].str.strip().astype(bool)]\n",
    "df = newdf[newdf['text'].str.strip().astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dafbb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62358 entries, 0 to 64892\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     62358 non-null  object\n",
      " 1   summary  62358 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97717a6f",
   "metadata": {},
   "source": [
    "## Text feature generation\n",
    "\n",
    "Now that we have done the text cleanup, we need to convert the text into numerical representations to be used by the model. This process is called feature generation. There are different ways to generate features out of text data. Here we will use one-hot vector[3] technique with some tweaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774afebe",
   "metadata": {},
   "source": [
    "### Define a class Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "182009c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cce7f",
   "metadata": {},
   "source": [
    "## Make the features ready for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2044c1a",
   "metadata": {},
   "source": [
    "### Define a function readData(text, summary) \n",
    "\n",
    "This takes text and summary as input. Here text and summary are two lists of strings. When we call this readData function, we will call it with our cleaned data X and Y respectively. This function does the following operations:\n",
    "Creates a tuple from text and summary as in pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "Creates input and output object by passing text and summary to the Lang class Note that we are only creating objects here. Not executing any other functions from the Lang class.\n",
    "Return input, output, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23b312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(text, summary):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
    "    \n",
    "    input_lang = Lang(text)\n",
    "    output_lang = Lang(summary)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549943e",
   "metadata": {},
   "source": [
    "### Define a function prepareData that takes list(df['text']) and list(df['summary']) as input.\n",
    "\n",
    "This prepareData function calls readData(X,Y) and gets back input, output, and pairs\n",
    "For each item in the pairs list, we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c2e0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2):\n",
    "    input_lang, output_lang, pairs = readData(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04995f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 62358 sentence pairs\n",
      "Counting words...\n",
      "['REGINA - A Saskatchewan university has cancelled all China trips it has organized for the next three months due to the spread of the coronavirus.\\nUniversity of Regina spokesman Paul Dederick says anyone who would have been involved in the travel has been advised.\\nHe says, effective immediately, all other travel to China by students, staff, faculty as part of student exchanges or research partnerships will require the dean\\'s approval and must include a plan on how to decrease health risks.\\nDederick says the measures are precautionary as the federal government has issued a travel advisory for China.\\nHealth officials in Ontario have confirmed Canada\\'s first case of the coronavirus and believe the patient\\'s wife to be the second case.\\nThey say the risk to Canadians is low.\\n\"As a precautionary measure the university is taking a pro-active approach to ensure faculty, staff and students travelling to and from China are aware of, and take steps to mitigate, their risk of contracting or spreading the virus,\" Dederick said in an email.\\nChina is reporting that the illness has infected more than 2,700 people and killed at least 81.\\nThis report by The Canadian Press was first published Jan. 27, 2020 Advertisement', 'University of Regina cancels travel to China due to coronavirus']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(list(df['text']), list(df['summary']))\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dce977",
   "metadata": {},
   "source": [
    "## Deliverable\n",
    "\n",
    "The deliverable is a Jupyter Notebook documenting your workflow. The end result of this notebook is a list of pairs of sentences. The 1st column in each row of this list is the text sentence and the 2nd column is the target/summary sentence. A sample output below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95a9d6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases Authors: FDA Pinworms of the red howler monkey (Alouatta seniculus) in Colombia: gathering the pieces of the pinworm-primate puzzle Publication date: Available online 4 December 2019Source: International Journal for Parasitology: Parasites and WildlifeAuthor(s): Brenda Solórzano-García, Andrés Link Ospina, Silvia Rondón, Gerardo Pérez-Ponce de LeónAbstractPinworms of primates are believed to be highly host specific parasites, forming co-evolutionary associations with their hosts. In order to assess the strength and reach of such evolutionary links, we need to have a broad understanding of the pinworm diversity associated with primates. Here, we employed an integrative taxonomic approach to assess pinworm divers... Parasitology Influences of cyclosporin A and non-immunosuppressive derivatives on cellular cyclophilins and viral nucleocapsid protein during human coronavirus 229E replication Publication date: January 2020Source: Antiviral Research, Volume 173Author(s): Yue Ma-Lauer, Yu Zheng, Miroslav Malešević, Brigitte von Brunn, Gunter Fischer, Albrecht von BrunnAbstractThe well-known immunosuppressive drug cyclosporin A inhibits replication of various viruses including coronaviruses by binding to cellular cyclophilins thus inactivating their cis-trans peptidyl-prolyl isomerase function. Viral nucleocapsid proteins are inevitable for genome encapsidation and replication. Here we demonstrate the interaction between the N protein of HCoV-229E and cyclophilin A, not cyclophilin B. Cyclophilin inhibitor...\n",
      "\n",
      "FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases\n"
     ]
    }
   ],
   "source": [
    "print(pairs[0][0])\n",
    "print()\n",
    "print(pairs[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b18669",
   "metadata": {},
   "source": [
    "## Build an Attention Based Deep Learning Model for Abstractive Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c9fca",
   "metadata": {},
   "source": [
    "### Define a Sequence-to-Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55cbc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max_len_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298cd05",
   "metadata": {},
   "source": [
    "#### Define the encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ceceb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc0b554",
   "metadata": {},
   "source": [
    " #### Define the class AttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "387ccf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ff523",
   "metadata": {},
   "source": [
    "#### Convert the training data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d295965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b6184",
   "metadata": {},
   "source": [
    "### Train a Sequence-to-Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8d8de4",
   "metadata": {},
   "source": [
    "#### The train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf3fbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_length):\n",
    "        try:\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
    "            encoder_outputs[i] = encoder_output[0, 0]\n",
    "        except IndexError:\n",
    "            print('Index Error in train')\n",
    "            print('index=',i)\n",
    "            print('input_length', input_length)\n",
    "            print('target_length', target_length)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982b26a",
   "metadata": {},
   "source": [
    "#### The trainIters method\n",
    "\n",
    "The trainIters method has 4 important parameters. You can have more parameters for debugging/logging purposes.\n",
    "\n",
    "- encoder: The encoder object of the Encoder class\n",
    "- decoder: The decoder object of the AttnDecoder class\n",
    "- num_iters: Number of iterations you want to train using the train method. This is an integer number.\n",
    "- learning_rate: Learning rate hyperparameter for your neural network. Feel free to use a default value for this parameter.\n",
    "\n",
    "We need to define the optimizers for encoder and decoder objects. These optimizers are gradient descent optimizers.\n",
    "\n",
    "Convert the training pairs to tensors\n",
    "\n",
    "Define the loss function. We are solving a classification problem, so we have to use a loss function that is commonly used in classification problems: log loss. In particular, here we will use negative log loss as criterion = nn.NLLLoss(). Refer to Understanding how LSTM works.\n",
    "\n",
    "Finally, we will call the train method num_iters times.\n",
    "\n",
    "We can save this loss output to look at the training loss over time. This helps us to debug the model and makes sure our model is improving over time.\n",
    "\n",
    "Add some log messages in the beginning and end of this method to keep track of the start and end of training such as starting training ... and end training ... as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d596be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97f3c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    print('Starting training ...')\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('Iteration', iter)\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    print('Stopping training ...')\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87385677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db51c4",
   "metadata": {},
   "source": [
    "#### Now actually train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "245c86d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training ...\n",
      "Iteration 50\n",
      "6m 11s (- 55m 41s) (50 10%) 7.0218\n",
      "Iteration 100\n",
      "12m 36s (- 50m 25s) (100 20%) 5.1913\n",
      "Iteration 150\n",
      "18m 1s (- 42m 3s) (150 30%) 6.5851\n",
      "Iteration 200\n",
      "24m 17s (- 36m 26s) (200 40%) 6.1937\n",
      "Iteration 250\n",
      "30m 53s (- 30m 53s) (250 50%) 6.3365\n",
      "Iteration 300\n",
      "36m 24s (- 24m 16s) (300 60%) 6.3908\n",
      "Iteration 350\n",
      "42m 58s (- 18m 25s) (350 70%) 6.4690\n",
      "Iteration 400\n",
      "48m 59s (- 12m 14s) (400 80%) 6.9316\n",
      "Iteration 450\n",
      "55m 0s (- 6m 6s) (450 90%) 6.8060\n",
      "Iteration 500\n",
      "61m 51s (- 0m 0s) (500 100%) 6.4888\n",
      "Stopping training ...\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 300\n",
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoder(hidden_size, output_lang.n_words, dropout=0.1).to(device)\n",
    "\n",
    "plot_losses = trainIters(encoder, decoder, 500, print_every=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c87222f",
   "metadata": {},
   "source": [
    "#### Save the model\n",
    "\n",
    "Save the model both as state_dict and the entire model.\n",
    "\n",
    "Not sure about this as there is no \"the model\". I am assuming that this refers to the encoder and the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "485c714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'encoder_weights.pth')\n",
    "torch.save(decoder.state_dict(), 'decoder_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec9dbcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder, 'encoder.pth')\n",
    "torch.save(encoder, 'decoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee97bde",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Logically it is similar to the train method. But there is no target. So, we feed the decoder’s output as decoder’s input of the next time step. Let’s define a method infer for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5b1ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70e2a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferRandomly(encoder, decoder, n=10):\n",
    "    f = open(\"evaluation_input.txt\", \"w\")\n",
    "    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = infer(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        f.write(pair[1]+','+output_sentence+'\\n')\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dfc41b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Employees-on-duty at the headquarters of the Bureau of Immigration (BI) voluntarily wore masks amid the risk of the 2019 novel coronavirus.\n",
      "Although there are still no confirmed novel coronavirus cases in the country, BI personnel remain vigilant by wearing masks to prevent any health risks.\n",
      "Immigration Spokesperson Krizia Sandoval said their employees in the main headquarters are transacting with hundreds of foreigners everyday, so they voluntarily decided to wear face masks.\n",
      "“For our front line personnel we advise them po to wear protective masks na rin wala namang mawawala kung sila ay magsusuot ng mga mask para po maprotektahan ang kanilang mga sarili (we advise them to wear protective masks. There is no harm in wearing one to protect yourself) ,” she said.\n",
      "The Immigration official also said that even the individuals visiting their offices are also wearing masks.\n",
      "The BI previously advised their front line personnel at airports to wear personal protective equipment like face masks for their protection. —AAC (with reports from Dante Amento)\n",
      "The post BI employees wear face masks amid risk of 2019-nCoV appeared first on UNTV News .\n",
      "= BI employees wear face masks amid risk of 2019-nCoV\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> Posted on 01/26/2020 3:11:29 PM PST by janetjanet998\n",
      "There are currently 2,493 confirmed cases worldwide, including 80 fatalities. TOPICS: Click The Pic To Donate\n",
      "Support FR, Donate Monthly If You Can Navigation: use the links below to view more comments. new numbers coming in from China\n",
      "371 new cases and 24 new deaths in Hubei province, China 1 posted on 01/26/2020 3:11:29 PM PST by janetjanet998 To: janetjanet998\n",
      "So glad there isnt a Budvirus. 2 posted on 01/26/2020 3:13:14 PM PST by SgtBob (Freedom is not for the faint of heart. Semper Fi!)\n",
      "= Coronavirus live thread 1-27\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> As space is chock-full of celestial objects and asteroids are some of the most common extraterrestrial objects, it's not so unusual that many of them fly past Earth. The size of some asteroids and the proximity of their trajectory to the Earth, however, make them a potential danger to our planet.\n",
      "An asteroid under the designated number 163373 and with an estimated diameter between 440 and 990 metres will fly past the Earth in February , NASA said. Astronomers Find Exceptionally Rare Asteroid Entirely Inside Venus’ Orbit The asteroid will reach its nearest point on 15 February, while at the same time it will be 15 times farther from our planet than the Moon.\n",
      "Asteroid 163373 was discovered on 23 October 1995 and was put in the Apollo group of asteroids that fly through the Earth's orbit, that's why they're considered potentially dangerous.\n",
      "The asteroid will pass near Earth again in 2075. ...\n",
      "= As if Deadly Coronavirus Wasn't Enough...Potentially Dangerous Asteroid to Fly Past Earth Next Month\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> on Thursday January 23, 2020 @10:43AM from the growing-concern dept. Huawei has postponed its upcoming HDC.Cloud developer conference as Chinese authorities try to control the spread of the deadly coronavirus detected in the southeastern city of Wuhan. From a report: The controversial company's event was going to take place in Shenzhen -- which lies more than 700 miles south of Wuhan -- Feb. 11-12, but it's been rescheduled to March 27-28. \"Based on the prevention and control of the pneumonia epidemic situation of the new coronavirus infection, we attach great importance to the health and safety of all the participants,\" Huawei said in its announcement. It also asked staff to avoid traveling to Wuhan and limit contact with animals, Reuters reported, and said it set up an outbreak prevention and control team in the city.\n",
      "= Huawei Postpones Its Developers Conference Over Deadly Coronavirus\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> News\n",
      "Ontario doctors have confirmed Canada’s first “presumptive positive case” of the deadly coronavirus .\n",
      "In a news conference Saturday, Ontario officials said a “presumptive positive” test result was recorded in Toronto after a man in his 50s who had travelled to Wuhan, China reported feeling ill on his return back to Canada.\n",
      "The man is now in stable condition in Sunnybrook Hospital.\n",
      "The illness, first detected last week in China, has infected more than 1,200 people and killed at least 41. The rapid spread has sparked Chinese authorities to place a number of cities on lock down.\n",
      "READ MORE: Wuhan bans cars, Hong Kong closes schools as coronavirus spreads\n",
      "Hong Kong leader Carrie Lam said earlier Saturday that her government will raise its response level to emergency, the highest one, and close primary and secondary schools for two more weeks on top of next week’s Lunar New Year holiday. They will re-open Feb. 17.\n",
      "The vast majority of the infections and all the deaths have been in mainland China, but fresh cases are popping up. Australia and Malaysia reported their first cases Saturday and Japan, its third. France confirmed three cases Friday, the first in Europe, and the U.S. identified its second, a woman in Chicago who had returned from China.\n",
      "The virus can display symptoms similar to the common cold or flu, including fever, coughing and difficulty breathing.\n",
      "No cases have been confirmed in B.C. as of now, but at least two Lunar New Year events in the Lower Mainland were cancelled this weekend out of concern over the infection.\n",
      "READ MORE: Saskatchewan lab joins global effort to develop coronavirus vaccine\n",
      "On Friday, the federal government downplayed any concerns over an outbreak getting into the country.\n",
      "Instead, Canada’s chief medical officer, Dr. Theresa Tam, said officials are focusing efforts on having international travellers flying into Toronto, Montreal and Vancouver who are experiencing flu-like symptoms self-report to border officers.\n",
      "– with files from The Canadian Press\n",
      "Like us on Facebook and follow us on Twitter . \n",
      "= ‘Presumptive case’ of coronavirus in Canada confirmed by Ontario doctors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< China coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> Romania for airport passengers coming from China Author: Sursa foto: Digi 24\n",
      "Romania's Health Minister Victor Costache said on Monday that special access lines for passengers coming from China were established at international airports. \"For several days now, a special access line has been operating at international airports for passengers coming from China, as well as for Chinese passengers. We also have a database and we know their location in Romania. All travellers coming from China receive some special questionnaires and they are requested to call 112, because their calls are taken over to identify this patient zero. I personally visited the units at the Matei Bals Institute, where these patients can be treated correctly, and the centres that I want to clearly identify at national level are - apart from Bucharest - Iasi, Targu Mures, Cluj, Timisoara, Sibiu and we identify an additional centre in Oradea,\" said Costache.He added that, starting on Tuesday morning, the Matei Bals Institute will be able to carry out tests to identify the coronavirus, which will also become possible next week at the healthcare facilities in the mentioned cities, which will receive reagents to detect the coronavirus.In the event that Romania faced people infected with coronavirus, according to him, the first ten will be treated at the Matei Bals Institute.\"The idea is not to bring all the cases to Bucharest. The first ten cases are to be treated in Bucharest, if we ever have these ten cases, and to create the expertise at national level,\" said Costache.About the seasonal flu, Costache said that this year the flu vaccination campaign will start in time.\n",
      "= Special access line opens in Romania for airport passengers coming from China\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> Menu Sections https://www.seattlepi.com/news/article/Alert-US-stocks-tumble-following-sell-off-in-15007120.php Alert: US stocks tumble following sell-off in Europe, Japan as coronavirus outbreak grows; Dow drops 500, travel companies sink Updated 6:35 am PST, Monday, January 27, 2020\n",
      "NEW YORK (AP) — US stocks tumble following sell-off in Europe, Japan as coronavirus outbreak grows; Dow drops 500, travel companies sink. Most Popular\n",
      "= Alert: US stocks tumble following sell-off in Europe, Japan as coronavirus outbreak grows; Dow drops 500, travel companies sink\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> FRIDAY, JAN 24, 2020 | 8 comments Chinese Coronavirus Outbreak Traced Back To Snakes, Study Finds The emergence of a new coronavirus strain in Wuhan, China last month has put the entire world on alert. Following the recent revelation that the virus can in fact be spread via human-to-human transmission, Chinese authorities have halted flights and trains departing the city and inhabitants have been advised not to travel. Meanwhile researchers have been working tirelessly to understand this new health risk, both its origins and nature, in order to formulate the best way to stop a full blown epidemic. Now, researchers appear to have zeroed in on how the virus, officially named 2019-nCoV by the World Health Organization, first spread to humans: exposure to snakes at a wholesale market.\n",
      "The study concludes that the first human diagnosed with this strain of coronavirus had, in all likelihood, visited a market in Wuhan where a large assortment of wildlife were available for purchase, including snakes, ...\n",
      "= NEWS: Chinese Coronavirus Outbreak Traced Back To Snakes, Study Finds\n",
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> Airline stocks were under additional pressure Tuesday after news that the mysterious coronavirus had claimed six lives and spread to Washington state.\n",
      "= Boeing halts shares trading after stock plunges by almost 6 percent\n",
      "< China coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n",
      "> Private hospitals asked to set aside ten beds\n",
      "Worried over a possible exposure to the novel coronavirus (2019-nCOV), which has infected a large number of people in China, South Korea, Japan, Thailand, and the United States, five more people with a travel history to China have self-reported to the State-run Rajiv Gandhi Institute of Chest Diseases (RGICD) since Monday night.\n",
      "Following reports of the outbreak spreading in China and its neighbouring countries, more people with a travel history to these countries are coming to the institute to get tested. Those with symptoms are being quarantined. As many as 3,275 passengers have been screened at the Kempegowda International Airport since January 20.\n",
      "Since January 24, a total of eight people were under observation. While one person, who was the first suspected case quarantined at the hospital, was discharged on Tuesday morning, another 40-year-old who had self-reported on Monday, refused to continue isolation in the hospital and instead requested home isolation.“We are sending him home on the condition that he will be under the supervision of surveillance officers.\n",
      "Apart from him, there are six more at the hospital now. While one reported late on Monday night, four came on Tuesday. All these six have a travel history to China (Chengdu, Beijing and Shangai) but not Wuhan. They have mild symptoms — runny nose and sore throat — and their samples have been sent to the National Institute of Virology (NIV), Pune for tests,” said RGICD Director C Nagaraja.\n",
      "Meanwhile, the State Health and Family Welfare Department has asked all private hospitals to set aside ten beds, exclusively for 2019-nCOV cases. “As some patients may prefer treatment in a private hospital, it is important that the private hospitals are equipped to handle the cases,” B.G. Prakash Kumar, State Joint Director (Communicable Diseases), told The Hindu on Tuesday.\n",
      "The department organised an orientation programme on the virus for doctors from both private and government hospitals. “We have shared standard guidelines and treatment protocol to be followed. We also communicated to them to set aside ten beds and they have agreed,” Dr. Prakash added. You have reached your limit for free articles this month. Register to The Hindu for free and get unlimited access for 30 days. Already have an account ? Sign in\n",
      "Sign up for a 30-day free trial. Sign Up Subscription Benefits Include Find mobile-friendly version of articles from the day's newspaper in one easy-to-read list. Unlimited Access Enjoy reading as many articles as you wish without any limitations. Personalised recommendations A select list of articles that match your interests and tastes. Faster pages Move smoothly between articles as our pages load instantly. Dashboard A one-stop-shop for seeing the latest updates, and managing your preferences. Briefing We brief you on the latest and most important developments, three times a day. Not convinced? Know why you should pay for news.\n",
      "= Coronavirus: 5 more quarantined in Bengaluru\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus coronavirus <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inferRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07a85770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16119_db21c91a1ab47385bb13773ed8238c31\r\n",
      "contraction_hashmap.py\r\n",
      "datasubset\r\n",
      "decoder.pth\r\n",
      "decoder_weights.pth\r\n",
      "encoder.pth\r\n",
      "encoder_weights.pth\r\n",
      "evaluation_input.txt\r\n",
      "__pycache__\r\n",
      "README.md\r\n",
      "Solution_Milestone_1.ipynb\r\n",
      "summarize-covid-19-news-using-nlp-and-pytorch.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f443a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
