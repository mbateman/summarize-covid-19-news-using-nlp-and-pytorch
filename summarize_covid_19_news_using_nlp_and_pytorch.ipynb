{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28670142",
      "metadata": {
        "id": "28670142"
      },
      "source": [
        "# Summarizing Covid-19 News Using NLP and Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0ea67bc",
      "metadata": {
        "id": "d0ea67bc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os, glob\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iYR0D0eRXg_",
        "outputId": "73d0ba4d-19f3-4f90-db0d-02cd76163851"
      },
      "id": "2iYR0D0eRXg_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f0bdd265",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0bdd265",
        "outputId": "347ae39a-b9b3-4db2-dde8-15ca77322b2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t81oUs7iS-CE",
        "outputId": "d23e7efb-f038-4993-a2b3-18fb947c3292"
      },
      "id": "t81oUs7iS-CE",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Colab Notebooks'\t  encoder_weights.pth\t       rouge_scores_01.txt\n",
            " contraction_hashmap.py   evaluation_input_01.txt      rouge_scores_h_500.txt\n",
            " datasubset\t\t  evaluation_input_h_500.txt   runs\n",
            " decoder_weights.pth\t  iTunes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('MyDrive/')\n",
        "from contraction_hashmap import contraction_map"
      ],
      "metadata": {
        "id": "FICxTEv0rnUX"
      },
      "id": "FICxTEv0rnUX",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5a7fac45",
      "metadata": {
        "id": "5a7fac45"
      },
      "outputs": [],
      "source": [
        "webhose_2019_12 = 'MyDrive/datasubset/16119_webhose_2019_12_db21c91a1ab47385bb13773ed8238c31_0000001.json'\n",
        "webhose_2020_01 = 'MyDrive/datasubset/16119_webhose_2020_01_db21c91a1ab47385bb13773ed8238c31_0000001.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2919a2de",
      "metadata": {
        "id": "2919a2de"
      },
      "source": [
        "## Extract News Data from the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179a7621",
      "metadata": {
        "id": "179a7621"
      },
      "source": [
        "### Download and extract the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ac48fd",
      "metadata": {
        "id": "b5ac48fd"
      },
      "source": [
        "Read each of those files, extract the value of the text key and title key from those objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5a27771c",
      "metadata": {
        "id": "5a27771c"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "target = []\n",
        "for filename in [webhose_2019_12, webhose_2020_01]:\n",
        "    with open(filename, 'r') as json_file:\n",
        "        json_list = list(json_file)\n",
        "\n",
        "    for json_str in json_list:\n",
        "        result = json.loads(json_str)\n",
        "        dataset.append(result['text'])\n",
        "        target.append(result['title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "739234d6",
      "metadata": {
        "id": "739234d6"
      },
      "source": [
        "The length of the list dataset and target will be 94403. So essentially our dataset size is about 100K."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f516f421",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f516f421",
        "outputId": "b8e13cbb-5216-49f7-e09f-eb6fed98c3da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(94403, 94403)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(dataset), len(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0b229d40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b229d40",
        "outputId": "1691207e-9744-4386-ac9f-3275b549d4a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Global Swine Healthcare Market by Products, Diseases & Geography – Forecast to 2024',\n",
              " 'FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases',\n",
              " 'C-Suite Awards: Regina Yan',\n",
              " 'FDA Launches Infectious Disease Crowdsourcing App for Clinicians FDA Launches Infectious Disease Crowdsourcing App for Clinicians',\n",
              " 'Drug Safety Oversight Board',\n",
              " 'How Prepared Are We For The Next Pandemic? Not Very, Experts Show',\n",
              " 'Suspected MERS case reported',\n",
              " 'Factors associated with and barriers to disclosure of a sexual assault to formal on-campus resources among college students - Mennicke A, Bowling J, Gromer J, Ryan C.',\n",
              " \"The effect of university students' violence tendency on their attitude towards domestic violence and the factors affecting domestic violence attitudes - Yagiz R, Sevil U, Guner Ö.\",\n",
              " 'YoYo Discusses Career, Teaching and Female Empowerment']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "target[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f65e3387",
      "metadata": {
        "id": "f65e3387"
      },
      "source": [
        "### Text cleanup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp5kQfTMWbak",
        "outputId": "2cd7b513-13b1-4946-c36e-20bf76d5a063"
      },
      "id": "Pp5kQfTMWbak",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c03a3ee6",
      "metadata": {
        "id": "c03a3ee6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower() # lowercase\n",
        "    text = text.split() # convert have'nt -> have not\n",
        "    for i in range(len(text)):\n",
        "        word = text[i]\n",
        "        if word in contraction_map:\n",
        "            text[i] = contraction_map[word]\n",
        "    text = \" \".join(text)\n",
        "    text = text.split()\n",
        "    newtext = []\n",
        "    for word in text:\n",
        "        if word not in stop_words:\n",
        "            newtext.append(word)\n",
        "    text = \" \".join(newtext)\n",
        "    text = text.replace(\"'s\",'') # convert your's -> your\n",
        "    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n",
        "    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n",
        "    text = re.sub(r'\\.',' . ',text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1ad25071",
      "metadata": {
        "id": "1ad25071"
      },
      "outputs": [],
      "source": [
        "X = [preprocess(text) for text in dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "afde2f45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afde2f45",
        "outputId": "139fa3aa-5ddb-456d-a361-9f0636c39165"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94403"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5040170a",
      "metadata": {
        "id": "5040170a"
      },
      "outputs": [],
      "source": [
        "Y = [preprocess(text) for text in target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e90ddda8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e90ddda8",
        "outputId": "79009a4f-49d4-497f-fb32-c874c5a6de85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94403"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6b1947d7",
      "metadata": {
        "id": "6b1947d7"
      },
      "outputs": [],
      "source": [
        "max_len_text = 600\n",
        "max_len_target = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "05c99e82",
      "metadata": {
        "id": "05c99e82"
      },
      "outputs": [],
      "source": [
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    if(len(target[i].split())<=max_len_target and len(dataset[i].split())<=max_len_text):\n",
        "        short_text.append(dataset[i])\n",
        "        short_summary.append(target[i])\n",
        "\n",
        "temp_df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ee7bb716",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ee7bb716",
        "outputId": "17091c0f-64da-42ba-a2d4-873fdf65ad65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  FDA launches app for health care professionals...   \n",
              "1  Of all of Regina Yan ’s many traits, an open m...   \n",
              "2  The CURE ID app allows clinicians to share and...   \n",
              "3  The DSB is composed of representatives from tw...   \n",
              "4  The Centre for Health Protection (CHP) of the ...   \n",
              "\n",
              "                                             summary  \n",
              "0  FDA launches app for health care professionals...  \n",
              "1                         C-Suite Awards: Regina Yan  \n",
              "2  FDA Launches Infectious Disease Crowdsourcing ...  \n",
              "3                        Drug Safety Oversight Board  \n",
              "4                       Suspected MERS case reported  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02c020c0-563c-4da5-bf50-5401f39e5425\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FDA launches app for health care professionals...</td>\n",
              "      <td>FDA launches app for health care professionals...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Of all of Regina Yan ’s many traits, an open m...</td>\n",
              "      <td>C-Suite Awards: Regina Yan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The CURE ID app allows clinicians to share and...</td>\n",
              "      <td>FDA Launches Infectious Disease Crowdsourcing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The DSB is composed of representatives from tw...</td>\n",
              "      <td>Drug Safety Oversight Board</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Centre for Health Protection (CHP) of the ...</td>\n",
              "      <td>Suspected MERS case reported</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02c020c0-563c-4da5-bf50-5401f39e5425')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02c020c0-563c-4da5-bf50-5401f39e5425 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02c020c0-563c-4da5-bf50-5401f39e5425');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "temp_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "fd40fa2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd40fa2a",
        "outputId": "196d3989-aca0-4d57-be45-2500ee32e48f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64893 entries, 0 to 64892\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   text     64893 non-null  object\n",
            " 1   summary  64893 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1014.1+ KB\n"
          ]
        }
      ],
      "source": [
        "temp_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "52b8743e",
      "metadata": {
        "id": "52b8743e"
      },
      "outputs": [],
      "source": [
        "newdf = temp_df[temp_df['summary'].str.strip().astype(bool)]\n",
        "df = newdf[newdf['text'].str.strip().astype(bool)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0dafbb98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dafbb98",
        "outputId": "0baee1c9-2a9f-449b-a2b7-e1cfde560103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 62358 entries, 0 to 64892\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   text     62358 non-null  object\n",
            " 1   summary  62358 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97717a6f",
      "metadata": {
        "id": "97717a6f"
      },
      "source": [
        "### Text feature generation\n",
        "\n",
        "Now that we have done the text cleanup, we need to convert the text into numerical representations to be used by the model. This process is called feature generation. There are different ways to generate features out of text data. Here we will use one-hot vector[3] technique with some tweaks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774afebe",
      "metadata": {
        "id": "774afebe"
      },
      "source": [
        "### Define a class Lang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "182009c9",
      "metadata": {
        "id": "182009c9"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252cce7f",
      "metadata": {
        "id": "252cce7f"
      },
      "source": [
        "### Make the features ready for the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2044c1a",
      "metadata": {
        "id": "e2044c1a"
      },
      "source": [
        "### Define a function readData(text, summary) \n",
        "\n",
        "This takes text and summary as input. Here text and summary are two lists of strings. When we call this readData function, we will call it with our cleaned data X and Y respectively. This function does the following operations:\n",
        "Creates a tuple from text and summary as in pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "Creates input and output object by passing text and summary to the Lang class Note that we are only creating objects here. Not executing any other functions from the Lang class.\n",
        "Return input, output, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f23b312d",
      "metadata": {
        "id": "f23b312d"
      },
      "outputs": [],
      "source": [
        "def readData(text, summary):\n",
        "    print(\"Reading lines...\")\n",
        "    \n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "    \n",
        "    input_lang = Lang(text)\n",
        "    output_lang = Lang(summary)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0549943e",
      "metadata": {
        "id": "0549943e"
      },
      "source": [
        "### Define a function prepareData that takes list(df['text']) and list(df['summary']) as input.\n",
        "\n",
        "This prepareData function calls readData(X,Y) and gets back input, output, and pairs\n",
        "For each item in the pairs list, we will do the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7c2e0caa",
      "metadata": {
        "id": "7c2e0caa"
      },
      "outputs": [],
      "source": [
        "def prepareData(lang1, lang2):\n",
        "    input_lang, output_lang, pairs = readData(lang1, lang2)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "04995f7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04995f7a",
        "outputId": "abaf6c5d-f7e5-4731-9b6f-436ebf1201f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 62358 sentence pairs\n",
            "Counting words...\n",
            "['Home\\nSelect Page Health experts issued an ominous warning about a coronavirus pandemic 3 months ago. Their simulation showed it could kill 65 million people.\\nPosted by Editor - Science News | Jan 23, 2020 | Science | 0 |\\nwuhan coronavirus\\nEmily Wang/AP Photo\\nA coronavirus that originated in Wuhan, China, has killed 18 people and infected more than 630.\\nThe virus has been reported in at least eight other countries, including the US, where a man in Washington who recently visited China was confirmed to have the illness .\\nA scientist at Johns Hopkins last year modeled what would happen if a deadly coronavirus reached a pandemic scale. His simulated scenario predicted that 65 million people could die within 18 months.', 'Health experts issued an ominous warning about a coronavirus pandemic 3 months ago. Their simulation showed it could kill 65 million people.']\n"
          ]
        }
      ],
      "source": [
        "input_lang, output_lang, pairs = prepareData(list(df['text']), list(df['summary']))\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37dce977",
      "metadata": {
        "id": "37dce977"
      },
      "source": [
        "## Deliverable\n",
        "\n",
        "The deliverable is a Jupyter Notebook documenting your workflow. The end result of this notebook is a list of pairs of sentences. The 1st column in each row of this list is the text sentence and the 2nd column is the target/summary sentence. A sample output below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "95a9d6a6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95a9d6a6",
        "outputId": "0bcabcff-a56a-4651-fe4c-74bac6b47a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases Authors: FDA Pinworms of the red howler monkey (Alouatta seniculus) in Colombia: gathering the pieces of the pinworm-primate puzzle Publication date: Available online 4 December 2019Source: International Journal for Parasitology: Parasites and WildlifeAuthor(s): Brenda Solórzano-García, Andrés Link Ospina, Silvia Rondón, Gerardo Pérez-Ponce de LeónAbstractPinworms of primates are believed to be highly host specific parasites, forming co-evolutionary associations with their hosts. In order to assess the strength and reach of such evolutionary links, we need to have a broad understanding of the pinworm diversity associated with primates. Here, we employed an integrative taxonomic approach to assess pinworm divers... Parasitology Influences of cyclosporin A and non-immunosuppressive derivatives on cellular cyclophilins and viral nucleocapsid protein during human coronavirus 229E replication Publication date: January 2020Source: Antiviral Research, Volume 173Author(s): Yue Ma-Lauer, Yu Zheng, Miroslav Malešević, Brigitte von Brunn, Gunter Fischer, Albrecht von BrunnAbstractThe well-known immunosuppressive drug cyclosporin A inhibits replication of various viruses including coronaviruses by binding to cellular cyclophilins thus inactivating their cis-trans peptidyl-prolyl isomerase function. Viral nucleocapsid proteins are inevitable for genome encapsidation and replication. Here we demonstrate the interaction between the N protein of HCoV-229E and cyclophilin A, not cyclophilin B. Cyclophilin inhibitor...\n",
            "\n",
            "FDA launches app for health care professionals to report novel uses of existing medicines for patients with difficult-to-treat infectious diseases\n"
          ]
        }
      ],
      "source": [
        "print(pairs[0][0])\n",
        "print()\n",
        "print(pairs[0][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b18669",
      "metadata": {
        "id": "c0b18669"
      },
      "source": [
        "## Build an Attention Based Deep Learning Model for Abstractive Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96c9fca",
      "metadata": {
        "id": "a96c9fca"
      },
      "source": [
        "### Define a Sequence-to-Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8d3cbd8c",
      "metadata": {
        "id": "8d3cbd8c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "writer = SummaryWriter('MyDrive/runs/summary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "55cbc6fa",
      "metadata": {
        "id": "55cbc6fa"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = max_len_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4298cd05",
      "metadata": {
        "id": "4298cd05"
      },
      "source": [
        "#### Define the encoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0ceceb3f",
      "metadata": {
        "id": "0ceceb3f"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc0b554",
      "metadata": {
        "id": "dfc0b554"
      },
      "source": [
        " #### Define the class AttnDecoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "387ccf5f",
      "metadata": {
        "id": "387ccf5f"
      },
      "outputs": [],
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e88ff523",
      "metadata": {
        "id": "e88ff523"
      },
      "source": [
        "#### Convert the training data to tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "d295965c",
      "metadata": {
        "id": "d295965c"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "856b6184",
      "metadata": {
        "id": "856b6184"
      },
      "source": [
        "### Train a Sequence-to-Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8d8de4",
      "metadata": {
        "id": "dc8d8de4"
      },
      "source": [
        "#### The train method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "cf3fbbab",
      "metadata": {
        "id": "cf3fbbab"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(input_length):\n",
        "        try:\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "            encoder_outputs[i] = encoder_output[0, 0]\n",
        "        except IndexError:\n",
        "            print('Index Error in train')\n",
        "            print('index=',i)\n",
        "            print('input_length', input_length)\n",
        "            print('target_length', target_length)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d982b26a",
      "metadata": {
        "id": "d982b26a"
      },
      "source": [
        "#### The trainIters method\n",
        "\n",
        "The trainIters method has 4 important parameters. You can have more parameters for debugging/logging purposes.\n",
        "\n",
        "- encoder: The encoder object of the Encoder class\n",
        "- decoder: The decoder object of the AttnDecoder class\n",
        "- num_iters: Number of iterations you want to train using the train method. This is an integer number.\n",
        "- learning_rate: Learning rate hyperparameter for your neural network. Feel free to use a default value for this parameter.\n",
        "\n",
        "We need to define the optimizers for encoder and decoder objects. These optimizers are gradient descent optimizers.\n",
        "\n",
        "Convert the training pairs to tensors\n",
        "\n",
        "Define the loss function. We are solving a classification problem, so we have to use a loss function that is commonly used in classification problems: log loss. In particular, here we will use negative log loss as criterion = nn.NLLLoss(). Refer to Understanding how LSTM works.\n",
        "\n",
        "Finally, we will call the train method num_iters times.\n",
        "\n",
        "We can save this loss output to look at the training loss over time. This helps us to debug the model and makes sure our model is improving over time.\n",
        "\n",
        "Add some log messages in the beginning and end of this method to keep track of the start and end of training such as starting training ... and end training ... as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d596be75",
      "metadata": {
        "id": "d596be75"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "10019ed4",
      "metadata": {
        "id": "10019ed4"
      },
      "outputs": [],
      "source": [
        "def variable2numpy(var):\n",
        "    \"\"\" For tensorboard visualization \"\"\"\n",
        "    return var.data.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "cb8af790",
      "metadata": {
        "id": "cb8af790"
      },
      "outputs": [],
      "source": [
        "def write_to_tensorboard(writer, loss, total_loss, encoder, decoder):\n",
        "    writer.add_scalars('loss in each iteration', {'loss':loss})\n",
        "    writer.add_scalars('total loss', {'total loss':total_loss})\n",
        "    \n",
        "    global_step = 1000\n",
        "\n",
        "    for name, param in encoder.named_parameters():\n",
        "        name = name.replace('.', '/')\n",
        "        writer.add_histogram('encoder/{}'.format(name), variable2numpy(param), global_step, bins='auto')\n",
        "        if param.grad is not None:\n",
        "            writer.add_histogram('encoder/{}/grad'.format(name), variable2numpy(param.grad), global_step, bins='auto')\n",
        "    \n",
        "    for name, param in decoder.named_parameters():\n",
        "        name = name.replace('.', '/')\n",
        "        writer.add_histogram('decoder/{}'.format(name), variable2numpy(param), global_step, bins='auto')\n",
        "        if param.grad is not None:\n",
        "            writer.add_histogram('decoder/{}/grad'.format(name), variable2numpy(param.grad), global_step, bins='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "97f3c358",
      "metadata": {
        "id": "97f3c358"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    print('Starting training with learning rate', learning_rate)\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    total_loss = 0\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        \n",
        "        total_loss +=loss\n",
        "        if write_summary:\n",
        "          write_to_tensorboard(writer, loss, total_loss, encoder, decoder)\n",
        "        \n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('Iteration', iter)\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    print('Stopping training ...')\n",
        "    return plot_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "87385677",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87385677",
        "outputId": "1f59c0eb-d346-4742-9a11-49035f9fcd2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9db51c4",
      "metadata": {
        "id": "a9db51c4"
      },
      "source": [
        "#### Now actually train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "245c86d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "245c86d7",
        "outputId": "068044ff-0c6e-4768-b90b-4570a545d1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with learning rate 0.005\n",
            "Iteration 100\n",
            "5m 36s (- 50m 24s) (100 10%) 6.7599\n",
            "Iteration 200\n",
            "10m 48s (- 43m 15s) (200 20%) 5.7328\n",
            "Iteration 300\n",
            "16m 11s (- 37m 47s) (300 30%) 5.9688\n",
            "Iteration 400\n",
            "21m 13s (- 31m 49s) (400 40%) 6.3284\n",
            "Iteration 500\n",
            "26m 8s (- 26m 8s) (500 50%) 5.9593\n",
            "Iteration 600\n",
            "31m 33s (- 21m 2s) (600 60%) 6.6362\n",
            "Iteration 700\n",
            "36m 11s (- 15m 30s) (700 70%) 6.1392\n",
            "Iteration 800\n",
            "41m 45s (- 10m 26s) (800 80%) 6.8075\n",
            "Iteration 900\n",
            "47m 14s (- 5m 14s) (900 90%) 6.8731\n",
            "Iteration 1000\n",
            "52m 10s (- 0m 0s) (1000 100%) 6.2673\n",
            "Stopping training ...\n"
          ]
        }
      ],
      "source": [
        "write_summary = False\n",
        "hidden_size = 300\n",
        "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoder(hidden_size, output_lang.n_words, dropout=0.1).to(device)\n",
        "\n",
        "plot_losses = trainIters(encoder, decoder, 1000, print_every=100, learning_rate=0.005)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c87222f",
      "metadata": {
        "id": "6c87222f"
      },
      "source": [
        "#### Save the model\n",
        "\n",
        "Save the model both as state_dict and the entire model.\n",
        "\n",
        "Not sure about this as there is no \"the model\". I am assuming that this refers to the encoder and the decoder."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_state = False\n",
        "save_model = False"
      ],
      "metadata": {
        "id": "w72HB1XgMQ-O"
      },
      "id": "w72HB1XgMQ-O",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "c24cfd1a",
      "metadata": {
        "id": "c24cfd1a"
      },
      "outputs": [],
      "source": [
        "if save_state:\n",
        "  torch.save(encoder.state_dict(), 'MyDrive/encoder_weights.pth')\n",
        "  torch.save(decoder.state_dict(), 'MyDrive/decoder_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "ec9dbcfb",
      "metadata": {
        "id": "ec9dbcfb"
      },
      "outputs": [],
      "source": [
        "if save_model:\n",
        "  torch.save(encoder, 'MyDrive/encoder.pth')\n",
        "  torch.save(decoder, 'MyDrive/decoder.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cee97bde",
      "metadata": {
        "id": "cee97bde"
      },
      "source": [
        "#### Inference\n",
        "\n",
        "Logically it is similar to the train method. But there is no target. So, we feed the decoder’s output as decoder’s input of the next time step. Let’s define a method infer for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "b5b1ec44",
      "metadata": {
        "id": "b5b1ec44"
      },
      "outputs": [],
      "source": [
        "def infer(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "70e2a482",
      "metadata": {
        "id": "70e2a482"
      },
      "outputs": [],
      "source": [
        "def inferRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        output_words, attentions = infer(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        with open('MyDrive/evaluation_input.txt','a') as out:\n",
        "            out.write('{}, {}\\n'.format(pair[1],output_sentence))\n",
        "            \n",
        "    out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "dfc41b6b",
      "metadata": {
        "id": "dfc41b6b"
      },
      "outputs": [],
      "source": [
        "inferRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca27f198",
      "metadata": {
        "id": "ca27f198"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c092b8e6",
      "metadata": {
        "id": "c092b8e6"
      },
      "source": [
        "### Evaluate summarization results with ROUGE score\n",
        "\n",
        "Install the rouge-score package pip install rouge-score.\n",
        "\n",
        "Write a python program that:\n",
        "\n",
        "- Reads each line from the evaluation_input.txt and creates a list of tuple input_pair. Each tuple consists of the first and last sentences from each line of the evaluation_input.txt.\n",
        "\n",
        "- Write a function called scoring(input_pair) that instantiates the rouge_scorer object as scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True).\n",
        "\n",
        "- And for each input pair, it calls the score function as:\n",
        "\n",
        "    for pair in input_pair:\n",
        "\n",
        "        scores = scorer.score(pair[0],pair[1])\n",
        "\n",
        "- Write these scores to a file\n",
        "\n",
        "Sample output from this should look like the following:\n",
        "\n",
        "{'rouge1': Score(precision=0.75, recall=0.6666666666666666, fmeasure=0.7058823529411765)}\n",
        "\n",
        "{'rouge1': Score(precision=1.0, recall=0.5, fmeasure=0.6666666666666666)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9csmpzqPgrvF",
        "outputId": "fa41ca62-6d4a-4f25-8dbd-5f6772348b7a"
      },
      "id": "9csmpzqPgrvF",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "e80c60f2",
      "metadata": {
        "id": "e80c60f2"
      },
      "outputs": [],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "\n",
        "def read_input(filename = 'MyDrive/evaluation_input.txt'):\n",
        "\n",
        "    with open('MyDrive/evaluation_input.txt', 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    f.close()\n",
        "    \n",
        "    input_pair = []\n",
        "    sentences = []\n",
        "    targets = [] \n",
        "    \n",
        "    for line in lines:\n",
        "        pair = line.split(',')\n",
        "        sentences.append(pair[0])\n",
        "        targets.append(pair[1])\n",
        "    \n",
        "    input_pair.append(sentences)\n",
        "    input_pair.append(targets)\n",
        "    \n",
        "    return input_pair\n",
        "\n",
        "\n",
        "def write_score(scores):\n",
        "    # write scores to a file. This file is the out of this milestone\n",
        "\n",
        "    with open('MyDrive/rouge_scores.txt', 'a') as f:\n",
        "        f.write(str(scores)+'\\n')\n",
        "    f.close()\n",
        "\n",
        "def scoring(input_pair):\n",
        "\n",
        "    with open('MyDrive/rouge_scores.txt', 'w') as f:\n",
        "        f.truncate()       \n",
        "    f.close()\n",
        "\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "    sentences = []\n",
        "    targets = []\n",
        "    sentences.extend(input_pair[0])\n",
        "    targets.extend(input_pair[1])\n",
        "    for pair in zip(sentences, targets):\n",
        "        scores = scorer.score(pair[0],pair[1])\n",
        "        write_score(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "6ff099c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ff099c5",
        "outputId": "7dccbee6-020d-421d-cf0f-25478d5d7c31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Saskatchewan lab joins global effort to develop coronavirus vaccine',\n",
              "  'Coronavirus hits United States',\n",
              "  'China confirms more cases of mystery viral pneumonia',\n",
              "  \"AHF • AHF Urges WHO to Immediately Declare New Coronavirus an Int'l Health Emergency\",\n",
              "  'PM Lee: We will continue to monitor the coronavirus situation closely and do more if necessary Blogs « Snippets',\n",
              "  'Gold Daily News: Wednesday',\n",
              "  'Person in WA being tested for coronavirus',\n",
              "  'Healthcare company Novacyt launches new coronavirus test | News | 1450 99.7 WHTC',\n",
              "  \"Butterfly Activist's Body Found After 53 Cops Detained - news\",\n",
              "  \"Here's how Ontario would respond to a real nuclear emergency\"],\n",
              " [' China of of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of <EOS>\\n',\n",
              "  ' January 29',\n",
              "  ' China of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of <EOS>\\n',\n",
              "  ' China of of of of of of of of of of <EOS>\\n']]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "read_input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "3df0f77a",
      "metadata": {
        "id": "3df0f77a"
      },
      "outputs": [],
      "source": [
        "input_pair = [['The quick brown fox jumps over the lazy dog', 'The quick brown dog jumps on the log.'],['my name is fox', 'my name']]\n",
        "scoring(input_pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "86a01037",
      "metadata": {
        "id": "86a01037",
        "outputId": "932e86de-84b8-475c-89fa-089cceccb442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: rouge_scores.txt: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cat rouge_scores.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "01863b32",
      "metadata": {
        "id": "01863b32"
      },
      "outputs": [],
      "source": [
        "scoring(read_input())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "165cddb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "165cddb9",
        "outputId": "74333017-2c88-4c25-fda7-793162f06b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.18181818181818182, recall=0.25, fmeasure=0.2105263157894737)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n",
            "{'rouge1': Score(precision=0.0, recall=0.0, fmeasure=0.0)}\n"
          ]
        }
      ],
      "source": [
        "!cat MyDrive/rouge_scores.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QmZRxKWTr1YB"
      },
      "id": "QmZRxKWTr1YB",
      "execution_count": 67,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1+"
    },
    "colab": {
      "name": "summarize-covid-19-news-using-nlp-and-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "97717a6f",
        "252cce7f"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}